{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install h5py to open files from the Amazon S3 servers.\n",
      "Please install h5netcdf to open files from the Amazon S3 servers.\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from monetio.models import cmaq\n",
    "from scipy import interpolate\n",
    "import geopandas\n",
    "\n",
    "# using geocube_env python environment (python 3.11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_cmaq_census(cmaq_file: str, census_file: str) -> pd.DataFrame:\n",
    "    \"\"\"Perform cubic spline interpolation of CMAQ PM2.5 output to census tract centers of population.\n",
    "\n",
    "    Args:\n",
    "        cmaq_file (str): Path to CMAQ pseudonetcdf file.\n",
    "        census_file (str): Path to census data point locations.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Census location input with PM2.5 field added.\n",
    "    \"\"\"\n",
    "    ds = cmaq.open_dataset(fname=cmaq_file)\n",
    "\n",
    "    # get annual average PM2.5\n",
    "    dapm = (\n",
    "        ds[\"PM25_AVG\"].mean(dim=\"time\").mean(dim=\"z\")\n",
    "    )  # taking mean of 1 level z to drop it\n",
    "\n",
    "    census_points = geopandas.read_file(census_file)\n",
    "\n",
    "    # transform pm2.5 and lat/long data into tidy dataframe\n",
    "    vals = [\n",
    "        dapm.values,\n",
    "        dapm.coords[\"longitude\"].values,\n",
    "        dapm.coords[\"latitude\"].values,\n",
    "    ]\n",
    "\n",
    "    pm25_df = pd.DataFrame(\n",
    "        [pd.DataFrame(x).stack() for x in vals],\n",
    "        index=[\"PM2.5\", \"longitude\", \"latitude\"],\n",
    "    ).T\n",
    "\n",
    "    # perform interpolation of annual average pm2.5 data to census points\n",
    "    census_points[\"pm25\"] = interpolate.griddata(\n",
    "        points=pm25_df[[\"longitude\", \"latitude\"]],\n",
    "        values=pm25_df[\"PM2.5\"],\n",
    "        xi=census_points[[\"LONGITUDE\", \"LATITUDE\"]],\n",
    "        method=\"cubic\",\n",
    "    )\n",
    "\n",
    "    return census_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rrice\\Miniconda3\\envs\\geocube_env\\Lib\\site-packages\\pyproj\\crs\\crs.py:1296: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems\n",
      "  proj = self._crs.to_proj4(version=version)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:       (TSTEP: 365, VAR: 14, DATE-TIME: 2, LAY: 1, ROW: 299, COL: 459)\n",
      "Dimensions without coordinates: TSTEP, VAR, DATE-TIME, LAY, ROW, COL\n",
      "Data variables: (12/15)\n",
      "    TFLAG         (TSTEP, VAR, DATE-TIME) int32 ...\n",
      "    O3_MDA8       (TSTEP, LAY, ROW, COL) float32 ...\n",
      "    O3_AVG        (TSTEP, LAY, ROW, COL) float32 ...\n",
      "    CO_AVG        (TSTEP, LAY, ROW, COL) float32 ...\n",
      "    NO_AVG        (TSTEP, LAY, ROW, COL) float32 ...\n",
      "    NO2_AVG       (TSTEP, LAY, ROW, COL) float32 ...\n",
      "    ...            ...\n",
      "    PM25_AVG      (TSTEP, LAY, ROW, COL) float32 ...\n",
      "    PM25_SO4_AVG  (TSTEP, LAY, ROW, COL) float32 ...\n",
      "    PM25_NO3_AVG  (TSTEP, LAY, ROW, COL) float32 ...\n",
      "    PM25_NH4_AVG  (TSTEP, LAY, ROW, COL) float32 ...\n",
      "    PM25_OC_AVG   (TSTEP, LAY, ROW, COL) float32 ...\n",
      "    PM25_EC_AVG   (TSTEP, LAY, ROW, COL) float32 ...\n",
      "Attributes: (12/34)\n",
      "    IOAPI_VERSION:  $Id: @(#) ioapi library version 3.1 $                    ...\n",
      "    EXEC_ID:        ????????????????                                         ...\n",
      "    FTYPE:          1\n",
      "    CDATE:          2021215\n",
      "    CTIME:          153223\n",
      "    WDATE:          2021215\n",
      "    ...             ...\n",
      "    GDNAM:          12US1           \n",
      "    UPNAM:          hr2day          \n",
      "    VAR-LIST:       O3_MDA8         O3_AVG          CO_AVG          NO_AVG   ...\n",
      "    FILEDESC:       Concentration file output                                ...\n",
      "    HISTORY:        \n",
      "    proj4_srs:      +proj=lcc +lat_1=33.0 +lat_2=45.0 +lat_0=40.0 +lon_0=-97....\n"
     ]
    }
   ],
   "source": [
    "# census block group level interpolation and join\n",
    "\n",
    "cmaq_file = \"C:\\\\Users\\\\rrice\\\\OneDrive - Environmental Protection Agency (EPA)\\\\exposure disparities\\\\EQUATES data\\\\HR2DAY_LST_ACONC_EQUATES_v532_12US1_2010.nc\"\n",
    "census_file = \"C:\\\\Users\\\\rrice\\\\OneDrive - Environmental Protection Agency (EPA)\\\\exposure disparities\\\\nhgis0002_shape\\\\nhgis0002_shapefile_cenpop2010_us_blck_grp_cenpop_2010\\\\US_blck_grp_cenpop_2010.shp\"\n",
    "adi_path = \"C:\\\\Users\\\\rrice\\\\OneDrive - Environmental Protection Agency (EPA)\\\\exposure disparities\\\\adi-download\\\\US_2020_ADI_Census Block Group_v3.2.csv\"\n",
    "dem_path = \"C:\\\\Users\\\\rrice\\\\OneDrive - Environmental Protection Agency (EPA)\\\\exposure disparities\\\\nhgis0002_csv\\\\nhgis0002_ds172_2010_blck_grp.csv\"\n",
    "\n",
    "census_points = interpolate_cmaq_census(cmaq_file, census_file)\n",
    "\n",
    "adi_df = pd.read_csv(adi_path)\n",
    "adi_df\n",
    "# join census demographic information\n",
    "\n",
    "dem_df = pd.read_csv(\n",
    "    dem_path,\n",
    "    encoding=\"cp1252\",\n",
    ").drop(\n",
    "    0\n",
    ")  # read census data, drop first line of data descriptions\n",
    "\n",
    "joined = (\n",
    "    census_points.set_index([\"GISJOIN\"])\n",
    "    .join(dem_df.set_index([\"GISJOIN\"]), how=\"outer\") # this join is good - same number of rows in each census_points and dem_df\n",
    "    .join(adi_df.set_index([\"GISJOIN\"]), how=\"left\") #TODO: figure out why there are more adi census block groups than from the census files?\n",
    "    .drop(\"geometry\", axis=\"columns\")\n",
    ")\n",
    "\n",
    "joined.to_csv(\"data/biol562 project dataset v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rrice\\Miniconda3\\envs\\geocube_env\\Lib\\site-packages\\pyproj\\crs\\crs.py:1296: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems\n",
      "  proj = self._crs.to_proj4(version=version)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:       (TSTEP: 365, VAR: 14, DATE-TIME: 2, LAY: 1, ROW: 299, COL: 459)\n",
      "Dimensions without coordinates: TSTEP, VAR, DATE-TIME, LAY, ROW, COL\n",
      "Data variables: (12/15)\n",
      "    TFLAG         (TSTEP, VAR, DATE-TIME) int32 ...\n",
      "    O3_MDA8       (TSTEP, LAY, ROW, COL) float32 ...\n",
      "    O3_AVG        (TSTEP, LAY, ROW, COL) float32 ...\n",
      "    CO_AVG        (TSTEP, LAY, ROW, COL) float32 ...\n",
      "    NO_AVG        (TSTEP, LAY, ROW, COL) float32 ...\n",
      "    NO2_AVG       (TSTEP, LAY, ROW, COL) float32 ...\n",
      "    ...            ...\n",
      "    PM25_AVG      (TSTEP, LAY, ROW, COL) float32 ...\n",
      "    PM25_SO4_AVG  (TSTEP, LAY, ROW, COL) float32 ...\n",
      "    PM25_NO3_AVG  (TSTEP, LAY, ROW, COL) float32 ...\n",
      "    PM25_NH4_AVG  (TSTEP, LAY, ROW, COL) float32 ...\n",
      "    PM25_OC_AVG   (TSTEP, LAY, ROW, COL) float32 ...\n",
      "    PM25_EC_AVG   (TSTEP, LAY, ROW, COL) float32 ...\n",
      "Attributes: (12/34)\n",
      "    IOAPI_VERSION:  $Id: @(#) ioapi library version 3.1 $                    ...\n",
      "    EXEC_ID:        ????????????????                                         ...\n",
      "    FTYPE:          1\n",
      "    CDATE:          2021215\n",
      "    CTIME:          153223\n",
      "    WDATE:          2021215\n",
      "    ...             ...\n",
      "    GDNAM:          12US1           \n",
      "    UPNAM:          hr2day          \n",
      "    VAR-LIST:       O3_MDA8         O3_AVG          CO_AVG          NO_AVG   ...\n",
      "    FILEDESC:       Concentration file output                                ...\n",
      "    HISTORY:        \n",
      "    proj4_srs:      +proj=lcc +lat_1=33.0 +lat_2=45.0 +lat_0=40.0 +lon_0=-97....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rrice\\AppData\\Local\\Temp\\ipykernel_21976\\527698670.py:10: DtypeWarning: Columns (1,3,4,6,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,51,52,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dem_df1 = pd.read_csv(dem_path1, encoding=\"cp1252\",).drop(\n",
      "C:\\Users\\rrice\\AppData\\Local\\Temp\\ipykernel_21976\\527698670.py:14: DtypeWarning: Columns (3,4,6,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dem_df2 = pd.read_csv(dem_path2, encoding=\"cp1252\",).drop(\n"
     ]
    }
   ],
   "source": [
    "# census tract level interpolation and join\n",
    "cmaq_file = \"C:\\\\Users\\\\rrice\\\\OneDrive - Environmental Protection Agency (EPA)\\\\exposure disparities\\\\EQUATES data\\\\HR2DAY_LST_ACONC_EQUATES_v532_12US1_2010.nc\"\n",
    "census_file = \"C:\\\\Users\\\\rrice\\\\OneDrive - Environmental Protection Agency (EPA)\\\\exposure disparities\\\\nhgis0003_shape\\\\US_tract_cenpop_2010.shp\"\n",
    "dem_path1 = \"C:\\\\Users\\\\rrice\\\\OneDrive - Environmental Protection Agency (EPA)\\\\exposure disparities\\\\nhgis0003_csv\\\\nhgis0003_ds172_2010_tract.csv\"\n",
    "dem_path2 = \"C:\\\\Users\\\\rrice\\\\OneDrive - Environmental Protection Agency (EPA)\\\\exposure disparities\\\\nhgis0003_csv\\\\nhgis0003_ds176_20105_tract.csv\"\n",
    "census_points = interpolate_cmaq_census(cmaq_file, census_file)\n",
    "\n",
    "# join census demographic information\n",
    "\n",
    "dem_df1 = pd.read_csv(dem_path1, encoding=\"cp1252\",).drop(\n",
    "    0\n",
    ")  # read census data, drop first line of data descriptions\n",
    "\n",
    "dem_df2 = pd.read_csv(dem_path2, encoding=\"cp1252\",).drop(\n",
    "    0\n",
    ")  # read census data, drop first line of data descriptions\n",
    "\n",
    "joined_tract = (\n",
    "    census_points.set_index([\"GISJOIN\"])\n",
    "    .join(dem_df1.set_index([\"GISJOIN\"]), how=\"outer\")\n",
    "    .join(dem_df2.set_index([\"GISJOIN\"]), how=\"outer\", rsuffix=\"_drop\")\n",
    "    .drop(\"geometry\", axis=\"columns\")\n",
    ")\n",
    "\n",
    "joined_tract[[x for x in joined_tract.columns.tolist() if \"_drop\" not in x]].to_csv(\n",
    "    \"data/biol562 project dataset census tract level v1.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geocube_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02f5aee9c095acc010af21d6ac44a0d6dd91c62d0bfd576cac18a3c41c244bae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
